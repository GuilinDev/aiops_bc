{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多 Agent 协作自动修复 K8s 故障\n",
    "\n",
    "1. 管理员 Agent\n",
    "2. 自动修复 Agent\n",
    "3. 寻求人类帮助 Agent\n",
    "4. 网络搜索 Agent\n",
    "5. 执行代码 Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langgraph langchain langchain_openai langchain_experimental langsmith pandas kubernetes openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入环境变量\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "# 定义函数，设置未定义的环境变量\n",
    "def _set_if_undefined(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
    "\n",
    "# 设置 OPENAI API 密钥\n",
    "_set_if_undefined(\"OPENAI_API_KEY\")\n",
    "_set_if_undefined(\"TAVILY_API_KEY\")\n",
    "\n",
    "import time\n",
    "from typing import Annotated\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "# 初始化两个工具\n",
    "tavily_tool = TavilySearchResults(max_results=5)\n",
    "# 执行 Python 代码的工具，谨慎使用\n",
    "python_repl_tool = PythonREPLTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义消息 Agent 的节点\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 定义一个消息代理节点，把结果封装成 HumanMessage 类型\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=name)]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 supervisor Agent 和调度逻辑\n",
    "# 管理员 Agent，负责决定下一个由哪个 Agent 来执行任务\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal,Sequence\n",
    "import operator\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "# 定义成员 Agent 和系统提示语，告诉 supervisor 要负责调度多个 Agent\n",
    "members = [\"Researcher\",\"Coder\",\"AutoFixK8s\",\"HumanHelp\"]\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers: {members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH.\"\n",
    ")\n",
    "options = [\"FINISH\"] + members\n",
    "\n",
    "# 定义 supervisor 的响应类，选择下一个执行的 Agent\n",
    "class routeResponse(BaseModel):\n",
    "    next: Literal[*options]\n",
    "\n",
    "# 创建提示语模板\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given the conversation above, who should act next?\"\n",
    "            \"Or should we FINISH Select one of: {options}\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "# 定义 LLM 模型和 supervisor_agent 函数\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "def supervisor_agent(state):\n",
    "    supervisor_chain = prompt | llm.with_structured_output(routeResponse)\n",
    "    return supervisor_chain.invoke(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 K8s 自动修复工具\n",
    "# 这里定义一个 K8s 自动修复工具，使用 OPENAI 模型生成 patch json\n",
    "from langchain_core.tools import tool\n",
    "from openai import OpenAI\n",
    "from kubernetes import client, config, watch\n",
    "import yaml\n",
    "\n",
    "config.load_kube_config()\n",
    "k8s_apps_v1 = client.AppsV1Api()\n",
    "\n",
    "@tool\n",
    "def auto_fix_k8s(deployment_name, namespace, event: str):\n",
    "    \"\"\"自动修复 K8s 问题\"\"\"\n",
    "    # 先根据 deployment_name 去获取 Deployment YAML\n",
    "    deployment = k8s_apps_v1.read_namespaced_deployment(\n",
    "        name=deployment_name, namespace=namespace\n",
    "    )\n",
    "    deployment_dict = deployment.to_dict()\n",
    "    # 移除不必要的字段\n",
    "    deployment_dict.pop(\"status\", None)\n",
    "    if \"metadata\" in deployment_dict:\n",
    "        deployment_dict[\"metadata\"].pop(\"managed_fields\", None)\n",
    "    \n",
    "    # 请求 OpenAI 生成修复的 Patch JSON\n",
    "    deployment_yaml = yaml.dump(deployment_dict)\n",
    "    OpenAIClient = OpenAI()\n",
    "    response = OpenAIClient.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        response_format={\"type\":\"json_object\"},\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"你是一个助理用来输出 JSON\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"你现在是一个云原生技术专家，现在你需要根据 K8s 的报错生成一个能通过 kubectl patch 的一段 JSON 内容来修复问题。\n",
    "        K8s 抛出的错误信息是：{event}\n",
    "        工作负载的 YAML 是：\n",
    "        {deployment_yaml}\n",
    "    你生成的 patch JSON 应该可以直接通过 kubectl patch 命令使用，除此之外不要提供其他无用的建议，直接返回 JSON，且不要把 JSON 放在代码块内\n",
    "    \"\"\",\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    json_opt = response.choices[0].message.content\n",
    "    print(json_opt)\n",
    "\n",
    "    # Apply Patch JSON\n",
    "    try:\n",
    "        k8s_apps_v1.patch_namespaced_deployment(\n",
    "            name=deployment_name,\n",
    "            namespace=namespace,\n",
    "            body=yaml.safe_load(json_opt)\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"修复失败：{str(e)}\")\n",
    "        return f\"修复失败：{str(e)}\"\n",
    "\n",
    "    return f\"工作自动修复成功！\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义人工帮助的 Tool\n",
    "# 用于在无法自动修复的时候发送飞书消息通知\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "@tool\n",
    "def human_help(event_message: str):\n",
    "    \"\"\"无法修复问题时寻求人工帮助\"\"\"\n",
    "    url = \"https://open.feishu.cn/open-apis/bot/v2/hook/d5e267dc-a92f-43d3-bc45-106b5e718c49\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    data = {\"msg_type\": \"text\", \"content\": {\"text\": event_message}}\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "    return \"寻求人类帮助成功，结束任务\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义工作流和 Graph（有向有环图）\n",
    "# 创建工作流，并且给节点添加 route 路由逻辑\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "import functools\n",
    "\n",
    "# 创建 research agent\n",
    "research_agent = create_react_agent(llm, tools=[tavily_tool])\n",
    "research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")\n",
    "\n",
    "# code agent\n",
    "code_agent = create_react_agent(llm, tools=[python_repl_tool])\n",
    "code_node = functools.partial(agent_node, agent=code_agent, name=\"Coder\")\n",
    "\n",
    "# auto fix agent\n",
    "auto_fix_agent = create_react_agent(llm, tools=[auto_fix_k8s])\n",
    "auto_fix_node = functools.partial(agent_node, agent=auto_fix_agent, name=\"AutoFixK8s\")\n",
    "\n",
    "# human help agent\n",
    "human_help_agent = create_react_agent(llm, tools=[human_help])\n",
    "human_help_node = functools.partial(agent_node, agent=human_help_agent, name=\"HumanHelp\")\n",
    "\n",
    "# 创建 Graph 并且添加节点\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Researcher\", research_node)\n",
    "workflow.add_node(\"Coder\", research_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_agent)\n",
    "workflow.add_node(\"AutoFixK8s\", auto_fix_node)\n",
    "workflow.add_node(\"HumanHelp\", human_help_node)\n",
    "\n",
    "# 定义路由逻辑\n",
    "for member in members:\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "\n",
    "conditional_map = {k:k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "\n",
    "workflow.add_edge(START, \"supervisor\")\n",
    "\n",
    "# 编译 Graph\n",
    "graph = workflow.compile()\n",
    "\n",
    "# 展示 Graph\n",
    "from IPython.display import display, Image\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 硬编码 Event 测试效果\n",
    "# for s in graph.stream(\n",
    "#     {\n",
    "#         \"messages\": [\n",
    "#             #HumanMessage(content=\"deployment: nginx, namespace: default, event: Back-off pulling image 'nginx:latess'\")\n",
    "#             HumanMessage(content=\"deployment: 'unkonw', namespace: 'default', event:  0/3 nodes are available: 1 Insufficient cpu, 2 Insufficient memory.\")\n",
    "#         ]\n",
    "#     }\n",
    "# ):\n",
    "#     if \"__end__\" not in s:\n",
    "#         print(s)\n",
    "#         print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 捕获和处理 K8s 事件\n",
    "# 监听 K8s 的产生，并且调用 Supervisor 处理事件\n",
    "\n",
    "config.load_kube_config()\n",
    "k8s_apps_v1 = client.AppsV1Api()\n",
    "core_v1 = client.CoreV1Api()\n",
    "\n",
    "w = watch.Watch()\n",
    "\n",
    "def run_stream(message: str):\n",
    "    for s in graph.stream(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=message)\n",
    "            ]\n",
    "        }\n",
    "    ):\n",
    "        if \"__end__\" not in s:\n",
    "            print(s)\n",
    "            print(\"----\")\n",
    "\n",
    "try:\n",
    "    namespace = \"default\"\n",
    "    for event in w.stream(\n",
    "        core_v1.list_namespaced_event, namespace=namespace, _request_timeout=None\n",
    "    ):\n",
    "        event_type = event[\"type\"]\n",
    "        event_object = event[\"object\"]\n",
    "\n",
    "        # 检查事件类型\n",
    "        if event_object.type == \"Warning\":\n",
    "            involved_object = event_object.involved_object\n",
    "            pod_name = involved_object.name\n",
    "            reason = event_object.reason\n",
    "            message = event_object.message\n",
    "\n",
    "            print(f\"Warning Event: {event_type} {pod_name} - {reason} - {message}\")\n",
    "\n",
    "            # 处理异常：Pod 可能不存在\n",
    "            try:\n",
    "                pod = core_v1.read_namespaced_pod(name=pod_name, namespace=namespace)\n",
    "                deployment_name = pod.metadata.labels.get(\"app\",\"unknown\")\n",
    "            except client.exceptions.ApiException as e:\n",
    "                print(f\"Error reading Pod {pod_name}: {e}\")\n",
    "                continue\n",
    "            \n",
    "            # 传递 Warning 事件到 run_stream()\n",
    "            try:\n",
    "                run_stream(f\"deployment: {deployment_name}, namespace: {namespace}, event: {reason} - {message}\")\n",
    "                time.sleep(10)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"Ignore non-warning event: {event_object.type} {event_object.reason} - {event_object.message}\")\n",
    "    \n",
    "finally:\n",
    "    w.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
